\chapter{関連研究}
\label{sec:related}

\section{画像認識}
\label{sec:rel-image}

近年，画像認識や画像検出を使った多くの応用が行われている．
この画像検出手法として最も利用されているアルゴリズムがBoosted Cascade\cite{Viola01rapidobject}である．
Boosted Cascadeは家庭用のパソコン程度の処理能力で人間の顔の様な複雑な画像をリアルタイムで検出することができる．
また専門家がパラメータチューンする必要もほとんどない．
これが多くの応用でBoosted Cascadeが利用されている理由である．
必要とする学習画像は，達成したい精度にもよるが，
顔検出を行う場合には顔の画像が5,000枚，顔以外の画像を3,000枚程度使った場合に90\%程度の検出率を達成することができる
\cite{Lienhart03empiricalanalysis}
.
顔以外の対象，例えば犬，柴犬，シャム猫といった対象をある程度以上の精度で画像検出する場合にも，
学習画像に5,000枚程度の検出対象の画像が必要となることが予測できる．
多くの場合，この大量の学習画像の収集は手動で行われている．
ImageNet\cite{imagenet}
の分類済みの画像を利用することも可能な場合もある．
しかしImageNetに存在しない画像，例えば発売されたばかりの新製品や新種の動物などを画像検出するには
人手で5,000枚の学習画像を用意する必要がある．
この作業をWebマイニングの技術を使って自動化するのが本研究の目的である．
ImageNetの画像を学習画像として利用可能な場合にも問題がある．
ImageNetの画像は学習したい対象のみが画像内に現れることが保証されていない．
例えば犬とタグのついた画像中に猫も写っている場合がある．
このためImageNetに既に分類されている画像であっても学習画像としてそのまま使うのは困難である．
この様な問題を間接的に解決する手法についても本研究では検討する．

大量の学習画像を用意しないといけない問題の解決方法として
類似画像を利用することで学習画像を減らす方法も提案されている．
Mirrashed\cite{Mirrashed_2013_ICCV}らは
スターウォーズのエイリアンの顔画像800枚から
高精度のエイリアンの顔画像検出器を学習させることに成功している．
この研究はエイリアンの顔画像と類似した
普通の人間の顔画像を学習に利用することで，
本来なら5,000枚の学習画像が必要となるところを
800枚の画像だけで高精度を実現している点に特徴がある．
本研究では
精度よりも
自動処理で手間を減らすことを主目的とし，
数百枚程度の学習画像を自動収集する方法について検討する．

なんらかのプログラムで自動収集した画像が全て正しい画像のみであることは稀である．
PaisitkriangkraiらはBoosted Cascadeの学習画像に間違いがどの程度までなら含まれても良いかを調査した
\cite{DBLP:journals/corr/abs-1009-5758}
.
Paisitkriangkraiらは学習画像を変形させノイズを加えると検出精度が５％ほど減少することを実験的に示した．
この研究は学習画像に間違いが含まれる割合についての調査ではないが，多少の間違いなら
画像検出器の精度を大幅には落とさないことを示している．
本研究では，作成するデータセットの画像枚数の3割程度までの間違いまでなら許容することとする．
Boosted CascadeはBoostingアルゴリズムに基づいており，
Boostingは自動的に学習データの間違いを除外する性質があることを考えると
3割程度の間違いは許容範囲内である．

\section{画像アノテーション}

画像アノテーションとは一般物体認識の要素課題の一つであり，
入力された画像が表す内容に対応するメタデータを付与する技術である．
% 本研究ではその中でも，予め画像と対応するメタデータを学習をしておくことで，
% 入力画像に自動でメタデータを付与する自動画像アノテーションを行う．
% 以下ではこのメタデータをラベルと呼ぶこととする．
%\section{一般的な手法}
一般的な自動画像アノテーションの概要を図\ref{fig:abst}に示す．

\begin{figure}[tb]
 \begin{center}
  \includegraphics[scale=0.50]{gaiyou.jpg}
 \end{center}
 \caption{一般的な画像アノテーション手法の概要}
 \label{fig:abst}
\end{figure}

まず第一段階として，画像を収集して
各画像にラベルまたはタグと呼ばれる画像の内容を表すテキストを付与する．
このラベルは人間が手動で記述する場合もあるが，
Web上の周辺テキストを伴った画像を使うことで自動推定する場合もある．
それらラベルを付けた画像の特徴を統計的に分析することで，ラベルの持つ特徴を学習する．
次に第二段階として，未知の画像を入力し，その画像特徴と類似する画像群が共通して持つラベルを見つけ，
入力画像にそのラベルを付与する．
この様にして入力された画像の内容を推測するのが画像アノテーションである．

% 本稿では，画像の分類手法に工夫をこらし，入力画像に対するラベル付与の精度を高めるための実験を行った．
自動画像アノテーションの分野における研究課題としては，
画像の収集や画像へのラベル付与を自動化することで，
大規模な画像データセットの構築にかかる時間と労力を減らす課題がある．
%\section{画像アノテーション}
%
%前節で
%ラベル付与の自動化・高精度化の手法が研究されていると述べた．
それらの研究の中でも近年頻繁に研究されているものが，画像のブロブ化である
\cite{duygulu,jeon}.
ブロブ化は各画像を複数の領域に分割し，隣接する領域との特徴の差異を見ることで画像全体を分解することで行う．
これによって得られたブロブは，画像に写っている物体ごとに分割されている可能性が高いので，
注目しているブロブ以外にある物体の有無に左右されることなく，そのブロブに対する精確なラベル付与が可能となる．
このブロブ化をデータセット内の全ての画像に施すことで，高精度の画像アノテーションを実現する．

Duygulu\cite{duygulu}らやJeon\cite{jeon}らは，すべての画像はブロブ(画像内の物体の塊)に単語を割り当てることで
内容物を記述することができるという前提で研究を行った．
JeonはDuyguluらの研究を元に，まずブロブと単語の同時分布を学習するためにCMRM(Cross-Media Relevance Model)を開発し，
更にそのモデルを改良した３つのモデルを開発した．
これらは画像を収集する際に自動で画像アノテーションを行う確率的生成モデルである．
その結果，Duyguluらが論文で公開した確率的生成モデルの画像アノテーションの平均精度0.20に比べ，
ほぼ倍の0.41という平均精度を示し，再現率についてもはるかによい結果となった．

またこれらの研究とは別のアプローチで画像アノテーションの精度向上を目指した研究がある．
渡邉ら\cite{watanabe}は，大規模Web画像データベースと
類似画像検索技術を用いた自動画像アノテーションシステムを実装した．
このシステムは，与えられた画像をクエリとして類似画像検索を行い，
検索結果の画像に付随するテキスト中の単語を確率的指標により評価することで，
特別な事前学習なしに画像を意味付けるキーワードを推定可能であることを示した．
このシステムを用いて5カテゴリ30概念の画像に対するアノテーションを行った結果，
10位内正解率がカテゴリ平均で43～75\%，全概念の平均で約59.1\%であった．

\section{テキスト処理}

Web上の周辺テキストを伴った画像から画像の内容を推定するのが画像アノテーションであるとみなすこともできる．
このような画像アノテーションの研究は多く存在する．
しかしテキスト処理として英語のテキスト処理を行うものが大部分である．
日本語の周辺テキストを処理する先行研究は発見することが出来なかった．
本研究では日本語テキスト処理を使った画像アノテーション手法を提案する．
%
ここでは
画像アノテーションを行うために
英語のテキスト処理と日本語のテキスト処理でどのような差があるのか
関連研究から推測する．

テキストの中の特定の対象を分類する問題の参考としてposタガーを考える．
ある研究では英語のposタガーの性能として約8割程度の精度が報告されている\cite{BirdKleinLoper09}.
%,Ibanez:2011:EPS:1964799.1964819
%日本語のposタガーの性能は約9割程度の精度であることが報告されている\cite{UniDicJp2010}．
%この結果はベンチマークや学習データの違いによって変わることがあるため単純に比較することはできないが，
またある研究では日本語のposタガーの性能として約9割程度の精度が報告されている\cite{UniDicJp2010}．
この結果はベンチマークや学習データの違いによって変わるため単純に比較することはできないが，
日本語テキスト処理の方が英語テキスト処理よりも精度が高い可能性を示している．
このことから周辺テキストが日本語の場合は，周辺テキストが英語の場合よりも高い精度で
画像アノテーションを実現できる可能性がある．
posタガーは単語の並んだ順番を処理する技法でもある．
このことから日本語の適当な手がかり表現を利用する手法は特に高い精度を達成できる可能性がある．

渡邉ら\cite{watanabe}の英語周辺テキストを利用した画像アノテーションの研究では，単純に単語の出現頻度を利用していた．
本研究では日本語の手がかり表現を利用した分類を行う．



%\chapter{類似画像検索とテキスト検索を用いた自動画像アノテーション}
\chapter{提案手法}
\label{sec:way}

%\section{概要}
ここでは本研究で提案する自動画像アノテーション手法を説明する．
図\ref{fig:way}に提案手法の概要を示す．
%
\begin{figure}[tb]
 \begin{center}
  \includegraphics[scale=0.50]{way.jpg}
 \end{center}
 \caption{提案手法の概要}
 \label{fig:way}
\end{figure}
%
提案手法は，ツイート収集，類似画像検索，テキスト検索の3段階で構成される．


%Webから得られた画像と周辺テキストを収集する前処理と，
%類似画像検索とテキスト検索を用いて得られた画像を分類する処理に分けられる．

最初のツイート収集処理においては，TwitterAPIを利用し，認識したい物体名をクエリに指定して検索を行い，得られたツイートを収集する．
収集したツイートに付随するURLから，Twitterの公式アップローダにアップロードされた画像を取得する．

次の類似画像検索処理においては，まずユーザが手作業でクエリとして選んだ物体を表す参考画像を一枚，事前に用意する．
参考画像とは，クエリを正しく表していると実験者が判断した画像であり，類似画像検索の比較元とする画像である．
この参考画像をクエリとして，収集した画像群から類似画像を選別する．
ここで類似画像とは，クエリとした画像と色や形状などの特徴が近い画像のことである．
本研究では参考画像の色ヒストグラムの分布と類似した色ヒストグラムを持つ画像を類似画像とした．
この結果，参考画像と見た目の類似した画像が選別される．
%%%
%参考画像の選別は人手で行う必要があるが，ImageNetを使って自動化することも出来る．
%しかしこの自動化の処理の実装は今後の課題である．

最後のテキスト検索処理においては，選別された画像に伴うツイート本文に
手がかり表現を用いてさらに選別を行う．
この手がかり表現とは，選別された画像に付随するテキストが何を表しているかの手がかりとなる表現のことである．
ツイート本文中からその表現を検索することで，
そのツイートに付随する画像がクエリを正しく表現しているか否かを判定する．

本研究では，この３つの処理を順次行うことで自動画像アノテーションを実現する．
類似画像検索処理とテキスト検索処理では異なる分類結果が与えられる．
この異なる分類結果の両方で正解と分類された結果を正解とする積集合処理の結果が提案手法である．
%%%
%どちらか片方の処理で正解と分類された結果を正解とする論理和処理の結果が提案手法である．
以下では，ツイート収集と，類似画像検索，テキスト検索について詳細に説明する．

\section{ツイート収集}
\label{sec:tweetCollect}
TwitterAPI1.1の機能を使い，検索したい画像の名称をクエリとし，ツイートを検索する．
この際，オプションとして “ -RT filter:images” をクエリに含める．
“-RT” は重複したツイートを取得することを避けるために追加した．
“filter:images” はTwitterの公式アップローダにアップロードされた画像のみを参照するために使用した．

次に収集した各ツイートから最後尾にあるURL部分を抜き出し，URL先からHTMLソースを入手する．
このHTMLソースから，正規表現でTwitterの公式アップローダに格納されている画像URLを抜き出し，
画像データをコピーして保存することで画像群を収集することができる．
この処理の際，ツイートしたユーザーが許可のない他者からツイート情報にアクセス出来ないようにしたり，
ツイートを消去したりすることによって，
収集したツイートのページや画像が格納されているアップローダのURLにアクセスできない場合がある．
このような場合これらのツイートは無視し，画像が正常に保存できたツイートのみを収集する．
%改めてデータベースに格納する．
これらの処理によって，収集したツイートと，ツイートに対応した画像のデータベースが作成できる．


\section{類似画像検索}
\label{sec:similar}

%%%色ヒストグラムは大学生向けの教科書に載っている話題なので本来なら詳細に説明する必要はありません.
%%%何か説明する必要があるのは色ヒストグラムについて何か特別な工夫を提案している場合のみです
提案手法では，各色が画像中に何ピクセルあるかを数えた色ヒストグラムの分布を画像の特徴量として扱い，
この分布が参考画像と類似している画像を類似画像として選別する．
色ヒストグラム処理は，
\url{http://aidiary.hatenablog.com/entry/20091003/1254574041}
で公開されているプログラムを参考に実装した．

色ヒストグラムはRGBの3色8ビットをそのままで計算すると16,777,216次元ベクトルとなり
計算にかかる時間が非常に大きくなる．
提案手法では各色を4分割した64色に減色した上でヒストグラムを算出する．
8ビットを4分割した2ビット，つまり0から3までを色番号として
%各番号は分けられた
代表値(0から63の場合は中心の32)の値に分類した．
例として
64色に減色した画像と，
その色ヒストグラムの棒グラフを
図\ref{fig:color}に示す．
%
\begin{figure}[tb]
 \begin{center}
  \includegraphics[scale=0.50]{colorhist.jpg}
 \end{center}
 \caption{色ヒストグラムの例}
 \label{fig:color}
\end{figure}
%
%
%OpenCVの色ヒストグラム類似度計測関数のドキュメントに色ヒストグラムを使う手法の詳細や参考文献が書いてあったはずなので色ヒストグラム処理の話を追加してください
図\ref{fig:color}左の犬の画像は
RGB値がそれぞれ32,96,160,224の4通りしかない．
各画素の色の種類は64色であるため，棒グラフの横軸は64個になっている．
横軸のビンの値は以下の式で表される．
\begin{eqnarray}
\mbox{bin} = (2^4 * R) + (2^2 * B) + (2^0 * G)
\end{eqnarray}
このときR,G,Bの値はそれぞれの色番号である．
例えば
図\ref{fig:color}右の棒グラフで
最も値の高いbin=20は(R,G,B)=(1,1,0)であり，
画像中で濃い黄緑が
広い面積をとっていることがわかる．

本手法では，取得した画像群から
参考画像と類似した画像を選別する．
そのため，クエリ対象を正しく表している
参考画像を事前に人手で選別しておかなければならない．
この処理はImageNetを使って自動化することも出来るが
ImageNetの分類カテゴリにない対象も多くある．
例えば犬の画像はImageNetから自動で収集できるが，
\ref{sec:experiment}章の実験でクエリ対象とした柴犬のカテゴリはImageNetには存在しない．
この様な場合もあるため本実装では参考画像の選別は手動処理としている．
%
選別された参考画像と収集した画像群は全て同じ320$\times$240サイズのJPEG形式に変換する．
これは色ヒストグラムを算出する際に，全ての画像において画素の記述方法を統一するためである．
次に，\ref{sec:tweetCollect}節で収集した画像と参考画像を減色した画像の色ヒストグラムを算出する.
%それぞれのデータを作成する．

次に参考画像のヒストグラムデータをクエリとして，
Histogram Intersection
の考え方を使って
類似度を算出する．
Histogram Intersectionとは
2つの色ヒストグラム
$H_1,H_2$
が与えられたときの類似度を
以下の式で与える手法である．
%
\begin{eqnarray}
\mbox{Similarity} = \frac{\sum_{i=0}^{63} min(H_1[i],H_2[i])}{\sum_{i=0}^{63} H_1[i]}
\end{eqnarray}
%
ここで$H_k$は$k$番目の画像の色ヒストグラムであり，
$H_k[i]$はそのヒストグラムの$i$番目のビンの値である．
%このとき2つのヒストグラムをH1,H2，ヒストグラムHのi番目のビンの値をH[i]と定義する．
なお，$H_1$はベースとなる参考画像のヒストグラムである．
この類似度は正規化がなされているため，値は0.0から1.0となり，
2つのヒストグラムが似ているほど大きな値をとる．
この類似度が設定した閾値を超えた画像を，クエリを表している画像として分類する．
閾値の設定方法については後述する．
%%%%%%%%%%閾値が明確に決められない場合にROCカーブを描いて性能を比較する場合も%%%%%%%%%%%%
%%閾値を 0 から1まで 0.01 ずつ大きくしていき，それぞれの閾値において類似画像検索の適合率と再現率を求める．%%
\section{テキスト検索}
\label{sec:textSearch}

本研究の目的はWebからの画像収集の自動化である．
Webには周辺テキストを伴った画像は大量に存在する．
そのため検出対象の母数はいくらでも大きくすることができる．
母数が巨大であるが収集したいのは高々数百枚程度の画像である．
そのため本研究では再現率は重視しない．
適合率のみを上げることに注目する．

\subsection{予備実験}
\label{sec:yobijikken}

予備実験として
\ref{sec:tweetCollect}節で説明した方法で収集したツイート集合から
犬と狐の画像を収集する実験を行った．
単純な手がかり表現として
“本物”，“写真”，“いる”，“撮”のいずれかの文字列とクエリ対象である“犬”または“狐”の文字を含むツイートを分類した．
この単純なテキスト分類の方法では，3割しか正解データを含んでいないデータセットしか得る事はできなかった．
しかし犬全般ではなく柴犬を検索したところ，4割以上とやや高い適合率を得ることができた．
猫全般と，猫の品種であるシャム猫，メインクーンについても同様の傾向がみられた．
そこで本研究では犬全般の様な広いカテゴリではなく柴犬の様な狭いカテゴリのみを検索対象にすることとする．
%犬全般をクエリとしたい場合は
%柴犬，シープドック，プードルなどの狭いカテゴリについての検索結果を合算することとする．
%この様なサブカテゴリはWordNetを使うことで得ることができる．

% この狭いカテゴリのみを扱う場合に適合率を向上させるために，
% 手がかり表現をさらに増やす方法を...

%そのための手がかり表現を次の方法で収集した．
%\ref{sec:tweetCollect}節で
%収集したツイートの本文から手がかり表現を見つけ，そのツイートの持つ画像を分類する．

\subsection{手がかり表現の収集とその利用方法}

次に手がかり表現をさらに増やすことで
%\ref{sec:yobijikken}節で使った手がかり表現よりも
適合率を上昇できないか検討する．
手がかり表現は，次の方法で収集する．
%
\ref{sec:tweetCollect}節の手法で犬，狐，猫のツイートを収集する．
これらの広いカテゴリの検索対象は提案手法では扱わないこととしている点に注意する．
こうして収集したツイートの中で犬，狐，猫の正解画像を含むツイートのみを人手で選別する．
そして選別したツイートに含まれる出現頻度の高い動詞，形容詞のみを選別する．
選別された動詞と形容詞の一部を
表\ref{tab:predicate}に示す．
こうして選別された単語を
１ツイート中に合計3つ以上含んでいるツイートを選択するのが提案手法である．
なお，
\ref{sec:experiment}章で行う本手法の評価実験では，この手がかり表現の収集に利用したツイートは除外している．
またこの3つという数は，抽出に使用したツイート1文から抽出できた動詞，形容詞の数の平均を採用した．
品詞の分類にはMecabバージョン0.996
\footnote{\url{http://mecab.googlecode.com/svn/trunk/mecab/doc/index.html}}
を利用した．


% 本手法で使用する手がかり表現は以下の手順で得る．
% まずTwitterから収集した画像付きツイートから，正しく画像の内容に言及しているツイートのみを人手で選別する．
% 選別したツイート群を言語処理にかけ，それぞれのツイートから動詞と形容詞を抽出する．
% 抽出した単語から重複をなくした集合を手がかり表現の集合とみなし，画像分類に用いる．
% なお，本手法で使用した手がかり表現の集合を得るために使用したツイートは，
% \ref{sec:examination}章で使用した複数のカテゴリのツイートを収集した際，
% 評価実験に使用しなかった一部のツイートから分類した合計100件のツイートである．
% また言語処理には形態素解析エンジンMecab
% （\url{http://mecab.googlecode.com/svn/trunk/mecab/doc/index.html}）のver0.996を使用し，
% ツイート中から分割された単語のうち品詞が動詞と形容詞のもののみを抽出したものを使用している．

% 抽出した手がかり表現の一部を表\ref{tab:predicate}に示す．

\begin{table}[bt]
\begin{center}
\caption{抽出された手がかり表現の一部}
\label{tab:predicate}
\begin{tabular}{|l|r|r|r|}\hline
動詞& 撮っ，佇む，持っ，する，たつ，吠え，飼い，笑っ，寝，見つかり，似，etc \\ \hline
形容詞& かわいい，よい，近かっ，ほしい，可愛い，人懐っこく，可愛，すっごい，etc \\ \hline
\end{tabular}
\end{center}
\end{table}

% \subsection{ツイート文の解析}

% 収集したツイートを1文ずつMecabにかけ，
% 手がかり表現の集合に含まれる単語がそのままの形でツイート文に含まれているか１つずつ調べ，
% １ツイート中に合計３つ以上の単語を含んでいるツイートの持つ画像は，
% クエリとして選んだ物体を表していると判断した．
% この３という数は，抽出に使用したツイート１文から抽出できた動詞，形容詞の数の平均を採用した．

\chapter{評価実験}
\label{sec:experiment}

ここでは提案手法に適していると考える狭いカテゴリの具体例として柴犬とシャム猫の画像の収集実験を行う．
広いカテゴリである犬一般の画像と猫一般の画像の収集については\ref{sec:examination}章で考察する．

\section{データセット}

%評価実験として提案手法で柴犬の画像を分類する実験を行い，分類結果の精度評価を行った．
%%本稿では，Twitterに投稿された画像付きツイートを収集し，データとして用いた．

柴犬の画像収集は以下の様に行った．
類似画像検索の入力である参考画像としてWikipedia\footnote{\url{http://ja.wikipedia.org/}}の柴犬の記事にある画像を使用した．
ツイートの収集は
2015年1月27日に，“柴犬 -RT filter:images”をクエリとして
\ref{sec:tweetCollect}節で紹介したようにツイートを収集した．
その結果として得られた3,462件のツイートと画像を収集した．
%これらのツイートと画像に参考画像を加えたものをデータセットとする．
このデータ群を提案手法でアノテーションすることで得られる最終的な分類結果の画像に，
どれだけ柴犬の画像が含まれているかを人手で評価し，適合率を算出した．
適合率は類似画像検索の分類結果に含まれる正解データの割合である．

同様にシャム猫の画像収集も行った．
Wikipediaのシャム猫の記事にある画像を参考画像として，
“シャム猫 -RT filter:images”をクエリとして得られた932件のツイートと画像を提案手法で分類し，
その分類結果の精度評価を行った．
%これらのツイートと画像をデータセットとした．

\section{実験結果}
\label{sec:expresult}

収集された画像を人手で分類した結果と，
提案手法で分類した結果を比較した
%本手法による結果を人手で分類し，画像分類精度を評価した
結果を表\ref{tab:result-shiba}に示す．
なお取得数と分類数，正解数の単位はいずれも枚である．

%まずデータセットの柴犬の画像3462枚とシャム猫の画像932枚に対し，
%各画像の色ヒストグラムデータを作成し，参考画像と比較して類似度を算出する．
%求めた類似度が設定した閾値を上回る画像を，クエリを表している画像として分類する．
%このとき閾値を0.58とした．
類似画像検索の処理で必要となる閾値は0.58とした．
この閾値は柴犬，シャム猫以外の対象に対して同様の実験を行い，そこで適当な閾値を手動で選別することで決定した．
類似画像検索で柴犬の画像であると判断した画像は1,338枚，シャム猫の画像であると判断した画像は430枚であった．

さらに分類した画像に対応するツイート文に対して
\ref{sec:textSearch}
節で説明したテキスト検索処理を行い，
条件を満たしたツイートに付随する画像を柴犬を表している画像として分類した．
この結果，柴犬の画像であると判断された画像は429枚，シャム猫の画像であると判断された画像は159枚となった．

%\section{評価}

柴犬をクエリとして得られた429枚の画像のうち，人手で柴犬を表していると判断できる画像は336枚であった．
シャム猫をクエリとして得られた159枚の画像のうち，人手で柴犬を表していると判断できる画像は132枚であった．
この結果から適合率を求めると，
提案手法によって得られた画像セットの適合率はそれぞれ約0.78,約0.83であり，
含まれる誤りの画像は2割程度であると判断できる．
これは\ref{sec:rel-image}節で述べた許容範囲内である3割を下回っており，
画像認識アルゴリズムのトレーニングセットとして十分に機能するといえる．

\begin{table}[tb]
\begin{center}
\caption{提案手法によって分類された柴犬とシャム猫の画像トレーニングセット精度}
\label{tab:result-shiba}
\begin{tabular}{|l|r|r|r|r|}\hline
& 取得数& 分類数& 正解数& 適合率（\%） \\ \hline \hline

柴犬& 3462& 429& 336& 0.78 \\ \hline
シャム猫& 932& 159& 132& 0.83 \\ \hline
\end{tabular}
\end{center}
\end{table}

\chapter{考察}
\label{sec:examination}

%本研究ではTwitterからの画像の収集方法について議論した．
本研究ではTwitterから画像を収集している．
一般的に１つのツイートに含まれる文は多くて3文程度である．
そのため係り受け解析によって詳細に検出対象の単語の前後の文章を解析することをしなくても，
単純に単語の共起関係を見るだけで文章の内容を推測できる．
ブログの様な長い文章が対象の場合には係り受け解析が必要となると推測される．
または長い文章ならば含まれる単語数も増えるため，単語の出現頻度のヒストグラムから内容を推測することもできる．
しかし単語の共起関係だけでおおよその内容が推測できるのはツイッターの特性である．
その反面Twitterでの検索結果には説明が困難な偏りが見られた．
具体的には犬，猫，狐などの画像をテキスト検索のみで探そうとすると非常に多くの関係ない画像が出現した．
こうした偏りの効果や提案手法の特性についてここでは考察する．


%\ref{sec:expresult}節で述べたように，
%柴犬をクエリにして得られた画像3462枚を提案手法で分類した結果，得られた画像数は429件となった．
%しかし本手法の各手順で，柴犬を表しているのに柴犬の画像ではないと判断されてしまった画像もある．
%この章では提案手法のうち2つの分類処理やその組み合わせが適切かどうか考察する．

%\section{考察実験}
\section{データセット}

提案手法では犬，猫，狐のような広いカテゴリは検索の対象としないとした．
しかしあえてこれらを検索対象とした場合の性能を示したのが
表\ref{tab:result-ex}である．

表\ref{tab:result-ex}の実験に使用した
データの収集は2015年1月27日に，“[カテゴリ名] -RT filter:images”をクエリとして
犬，猫，狐，椅子，メインクーンのツイートを収集し，
収集したツイート中から無作為にそれぞれ300件ずつツイートを選び，対応する画像を取得した．
ただしメインクーンについてはクエリを含むツイートが少なく，
192件しか取れなかった．
%犬，猫，狐はある程度大きなカテゴリの中で，Twitterに画像がありそうなものを選んだ．
%椅子は動物以外での分類精度を確かめるために選んだ．
%メインクーンは評価実験に使用した柴犬やシャム猫と同程度の広さのカテゴリの結果を知るために選んだ．
%
%取得できたツイートと画像に参考画像を加えたものを，各カテゴリのデータセットとする．
こうして収集した画像を人手で判別した結果と提案手法で判別した結果の比較を行った．
%ておき，各分類手法でどれだけの適合率で画像を分類できたかを評価する．
人手での判別の際，クエリが動物であればその動物の顔が半分以上見えていれば正解とした．
クエリが椅子の場合は，人や物などの障害物が画像中に写っている場合であっても
椅子のほぼ全体が画像内に収まっているものを正解とした．

表\ref{tab:result-ex}では，収集した最大300枚の画像またはツイートを対象に，
類似画像検索のみを使用した場合を（１），
テキスト検索のみを使用した場合を（２）と表した．
% ，類似画像検索とテキスト検索の和（１∪２），
% 提案手法である類似画像検索とテキスト検索の積（１∩２）の分類の4手法である．
% 表\ref{tab:result-ex}において
(1 $\cup$ 2)
は類似画像検索の分類結果とテキスト検索の分類結果の和集合を分類結果として扱う場合を表す．
(1 $\cap$ 2)
は類似画像検索の分類結果とテキスト検索の分類結果の積集合を分類結果として扱う場合を表す．

%実験結果の再現率，適合率，F 値をまとめたものを表\ref{tab:result-ex}に示す．
ここで，再現率は人手で判定したクエリを表す画像のうち実際に分類できていた正解データ画像の割合である．
さらに，求めた再現率および適合率から F 値を算出する．
F 値（$F\verb|-|measure$）は適合率（$precision$）と再現率（$recall$）の調和平均であり，次式で求める．

\begin{eqnarray}
F\verb|-|measure = \frac{2・precision・recall}{precision+recall}
\end{eqnarray}

\section{各カテゴリの分類結果の特徴}
%\section{偏りの効果}

Twitterにおいて，ツイートと画像のある種のミスマッチの影響が特に顕著に見られるのが狐についての結果である．
狐で得られた画像を人手で分類した結果，300枚中7枚しか正解と判別できなかった．
狐のカテゴリでは収集した画像に狐が写っている画像が極端に少なく，
その分類結果はの評価は困難であった．
これは狐が身近にいる動物ではないため，狐の姿を表す画像が少なく，
代わりにイラストが多く含まれていたことが理由としてあげられる．
また，これは狐という単語には動物として狐以外の様々な意味を内包している事が原因ではないかと考えられる．
例えばブラウザのFirefoxを“狐”と表現する場合などがある．

犬と猫に対しても狐ほどではないが類似したミスマッチが見られた．
クエリ“犬”で得られた画像を人手で分類した結果は，300枚中130枚が正解となった．
クエリ“猫”で得られた画像を人手で分類した結果は，300枚中105枚が正解となった．
検索対象を直接表す単語をTwitterの検索APIに入力しているにも関わらず2/3が目的の対象以外の画像であった．
しかし類似画像検索を使って間違った画像を除外することで，適合率は約6割を達成できている．
テキスト検索はあまり効果をあげておらず適合率は4割程度である．
しかし類似画像検索とテキスト検索の結果の積集合をとると7割程度の適合率を実現している．
これは場合によっては広いカテゴリを対象としたクエリも利用できる可能性があることを示唆している．
ただしこのときの再現率は3割以下であり収集できた画像は30枚以下であった．
これはクエリの種類によっては数枚しか画像が収集できない可能性を示しており，
サブカテゴリでの検索の方が安全であることが推測される．

メインクーンは猫の種類の１つである．
クエリ“メインクーン”で得られた画像を人手で分類した結果は，192枚中142枚が正解と判別できた．
過半数が対象の画像であり，より狭いサブカテゴリでの検索は高い適合率を達成できることを示している．
特に類似画像検索とテキスト検索の結果の積集合の結果は分類した全ての画像が正解となっている．
しかし類似画像検索の再現率は1割となっている．
メインクーンの収集画像を見ると
毛色や撮る状況によって，色の分布が他の動物より大きく変動している様子がみられた．
これが類似画像検索の再現率を下げていると考えられる．


クエリ“椅子”で得られた画像を人手で分類した結果は，300枚中149枚が正解と判別できた．
椅子のカテゴリの分類結果は，全体的に犬より悪い結果となっている．
これは，椅子を表すツイートにおいて動詞や形容詞があまり使われておらず，
抽出した手がかり表現の集合にも椅子に適した表現が少なかったことがあげられる．

\begin{table}%[tb]
\begin{center}
\caption{各カテゴリの分類における再現率，適合率，F値}
\label{tab:result-ex}
\begin{tabular}{|l|r|r|r|r|}\hline
&& 再現率& 適合率& F値\\ \hline \hline
犬
& 類似画像検索(1)& 0.246& 0.640& 0.356 \\ \cline{2-5}
& テキスト検索(2)& 0.669& 0.446& 0.535 \\ \cline{2-5}
& 提案手法(1$\cup$2)& 0.792& 0.464& 0.585 \\ \cline{2-5}
& 提案手法(1$\cap$2)& 0.123& 0.696& 0.209 \\ \hline
猫
& 類似画像検索(1)& 0.371& 0.582& 0.453 \\ \cline{2-5}
& テキスト検索(2)& 0.610& 0.372& 0.462 \\ \cline{2-5}
& 提案手法(1$\cup$2)& 0.705& 0.372& 0.487 \\ \cline{2-5}
& 提案手法(1$\cap$2)& 0.276& 0.725& 0.400 \\ \hline
狐
& 類似画像検索(1)& 0.571& 0.095& 0.163 \\ \cline{2-5}
& テキスト検索(2)& 0.429& 0.016& 0.031 \\ \cline{2-5}
& 提案手法(1$\cup$2)& 0.571& 0.020& 0.039 \\ \cline{2-5}
& 提案手法(1$\cap$2)& 0.429& 0.100& 0.162 \\ \hline
椅子
& 類似画像検索(1)& 0.309& 0.500& 0.382 \\ \cline{2-5}
& テキスト検索(2)& 0.497& 0.411& 0.450 \\ \cline{2-5}
& 提案手法(1$\cup$2)& 0.678& 0.479& 0.561 \\ \cline{2-5}
& 提案手法(1$\cap$2)& 0.128& 0.613& 0.211 \\ \hline
メインクーン
& 類似画像検索(1)& 0.106& 0.882& 0.189 \\ \cline{2-5}
& テキスト検索(2)& 0.606& 0.775& 0.680 \\ \cline{2-5}
& 提案手法(1$\cup$2)& 0.648& 0.773& 0.705 \\ \cline{2-5}
& 提案手法(1$\cap$2)& 0.063& 1.000& 0.119 \\ \hline
\end{tabular}
\end{center}
\end{table}

\section{類似画像検索による画像分類精度評価}
類似画像検索の分類精度は，全体的に再現率が低く，適合率が高い傾向にある．
適合率が高い理由としては，参考画像として人手で確実に正解の画像を選ぶので，
類似画像検索では正解に近い色の分布を持つものしか分類しないからである．
逆に，再現率が低いのは，分類する数が少ないため，
その中に含まれる正解データも必然的に少なくなることが理由である．
設定した閾値が0.58と高めであるため，犬，猫，狐では分類結果の画像数も300中約50とかなり少ない．
改良案としては，類似画像検索に使う閾値を分類するカテゴリごとに分けることや，
類似画像検索に使用する特徴量を変えることがあげられる．

\section{テキスト検索による画像分類精度評価}

テキスト検索の分類では，基本的に多くの画像をそのカテゴリの画像に分類しており再現率が高い傾向がある．
これは，手がかり表現の集合に基本的な動詞などが含まれているため，
多くのツイートがこの分類条件に当てはまっていることが理由である．
その結果，全体的に再現率が高く適合率が少し低めとなっている．
しかし猫，犬，椅子を分類した結果のF値は0.5程度であり，
改良の余地はまだ大きい．

\section{2手法の組み合わせによる画像分類精度評価}
類似画像検索とテキスト検索，2手法の検索結果の和集合(1$\cup$2)では，
狐以外の全カテゴリにおいていずれか１つの手法による分類結果よりF値が高くなっている．
これは，分類される画像の割合が増えた以上に，その結果に含まれる正解データの割合が増えたためである．
反面，分類結果には多くの間違いも含まれており，
画像認識のトレーニングセットとして使えるまでには至っていない．

しかし，2手法の結果の積集合(1$\cap$2)ではF値が極端に低く，
各カテゴリの画像に分類される画像自体が少ない．
その代わりにその中に含まれる正解データの割合は非常に高くなっている．
犬や猫は7割近い適合率となり，椅子の結果でも6割の適合率を持っている．
これらのことから，現状の2手法の組み合わせとしては積集合が有用であることがわかる．
しかし，分類の結果得られた画像はかなり少ない．

この手法を使用した提案手法では多くのツイートを取得したため，
画像認識アルゴリズムのトレーニングセットとして利用するのに十分な画像量となったが，
身近に居ない狐のように正解の画像が少なくなることが予想される
画像は収集してもトレーニングセットとして使用できないと思われる．
しかし，本研究の目的のような狭い範囲のカテゴリにおける画像分類には，
提案手法にも収集作業を繰り返すことである程度利用できることがわかる．
